{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7eb469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3c0f6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 만나서 정말 반가워요.\n",
      "저는 성격과 대화를 기반으로 공감하고 상담해주는 챗봇이에요.\n",
      "질문자님의 MBTI 성향을 함께 알아보고, 고민이 있다면 꼭 함께 나눠요.\n",
      "그럼 가볍게 대화하며 성향부터 함께 살펴볼까요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"안녕하세요! 만나서 정말 반가워요.\")\n",
    "print(\"저는 성격과 대화를 기반으로 공감하고 상담해주는 챗봇이에요.\")\n",
    "print(\"질문자님의 MBTI 성향을 함께 알아보고, 고민이 있다면 꼭 함께 나눠요.\")\n",
    "print(\"그럼 가볍게 대화하며 성향부터 함께 살펴볼까요?\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 성향을 유도하는 질문 리스트 (E/I, S/N, T/F, J/P 커버)\n",
    "mbti_questions = [\n",
    "    \"사람들과 함께 있을 때 에너지가 충전되나요, 아니면 혼자 있을 때 편안함을 느끼나요?\",\n",
    "    \"일정을 철저히 계획하는 걸 좋아하나요, 즉흥적인 순간을 더 선호하나요?\",\n",
    "    \"결정을 내릴 때 감정에 따라 움직이는 편인가요, 논리적으로 판단하나요?\",\n",
    "    \"정해진 규칙과 구조 안에서 일하는 걸 좋아하나요, 자유롭고 유연한 환경을 선호하나요?\",\n",
    "    \"주말에 쉬는 시간이 주어진다면 무엇을 하시고 싶나요?\",\n",
    "    \"타인의 감정을 빨리 알아채는 편인가요?\",\n",
    "    \"새로운 아이디어나 상상을 자주 하나요?\",\n",
    "    \"정답보다 다양한 관점을 이해하려는 편인가요?\",\n",
    "    \"계획이 어긋날 때 스트레스를 받나요?\",\n",
    "    \"처음 만난 사람과 대화를 이어가는 것이 편한가요?\"\n",
    "]\n",
    "\n",
    "user_answers = []\n",
    "\n",
    "for i, q in enumerate(mbti_questions):\n",
    "    answer = input(f\"Q{i+1}. {q}\\nA{i+1}: \")\n",
    "    user_answers.append(answer.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3de265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 응답 리스트(answers)를 입력받아, GPT를 통해 MBTI를 추론하는 함수\n",
    "def predict_mbti_from_conversation(answers):\n",
    "    # 질문-답변을 한 문장씩 정리\n",
    "    formatted = \"\\n\".join([f\"Q{i+1}: {mbti_questions[i]}\\nA{i+1}: {a}\" for i, a in enumerate(answers)])\n",
    "    \n",
    "    # GPT 시스템 메시지: 성격 분석가로서 MBTI 유형만 4글자로 추론하도록 지시\n",
    "    system_msg = (\n",
    "        \"당신은 성격 분석가입니다. 다음 사용자와의 대화를 기반으로 MBTI 유형을 하나로 추정해주세요. \"\n",
    "        \"추정된 MBTI만 대문자 4글자로 출력해주세요 (예: INFP).\"\n",
    "    )\n",
    "    \n",
    "    # GPT API 호출\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": formatted}\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        max_tokens=10\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message[\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a51266",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predicted_mbti_output = \u001b[43mpredict_mbti_from_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_answers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 예측 결과 예: \"예상 MBTI는 INTP입니다. 혼자 있는 걸 선호하고, 유연한 사고방식과 논리 기반 결정을 선호합니다.\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGPT 기반 예측 결과:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, predicted_mbti_output)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mpredict_mbti_from_conversation\u001b[39m\u001b[34m(user_answers)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 프롬프트: 16가지 MBTI 중 하나만 예측하고 간단한 이유 포함\u001b[39;00m\n\u001b[32m      9\u001b[39m system_msg = (\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m당신은 성격 심리 전문가입니다.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m아래 사용자의 답변을 분석해서 가장 적합한 MBTI를 하나 예측해주세요.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m16가지 유형 중 하나로 대답하고, 이유는 2~3줄로 설명해주세요.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_msg\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m].strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cosmi\\.venv\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[39m, in \u001b[36mChatCompletion.create\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time.time() > start + timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cosmi\\.venv\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:149\u001b[39m, in \u001b[36mEngineAPIResource.create\u001b[39m\u001b[34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    136\u001b[39m     **params,\n\u001b[32m    137\u001b[39m ):\n\u001b[32m    138\u001b[39m     (\n\u001b[32m    139\u001b[39m         deployment_id,\n\u001b[32m    140\u001b[39m         engine,\n\u001b[32m    141\u001b[39m         timeout,\n\u001b[32m    142\u001b[39m         stream,\n\u001b[32m    143\u001b[39m         headers,\n\u001b[32m    144\u001b[39m         request_timeout,\n\u001b[32m    145\u001b[39m         typed_api_type,\n\u001b[32m    146\u001b[39m         requestor,\n\u001b[32m    147\u001b[39m         url,\n\u001b[32m    148\u001b[39m         params,\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__prepare_create_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     response, _, api_key = requestor.request(\n\u001b[32m    154\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m         request_timeout=request_timeout,\n\u001b[32m    161\u001b[39m     )\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    164\u001b[39m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cosmi\\.venv\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:106\u001b[39m, in \u001b[36mEngineAPIResource.__prepare_create_request\u001b[39m\u001b[34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout == \u001b[32m0\u001b[39m:\n\u001b[32m    104\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = MAX_TIMEOUT\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m requestor = \u001b[43mapi_requestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIRequestor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m url = \u001b[38;5;28mcls\u001b[39m.class_url(engine, api_type, api_version)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    115\u001b[39m     deployment_id,\n\u001b[32m    116\u001b[39m     engine,\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     params,\n\u001b[32m    125\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cosmi\\.venv\\Lib\\site-packages\\openai\\api_requestor.py:138\u001b[39m, in \u001b[36mAPIRequestor.__init__\u001b[39m\u001b[34m(self, key, api_base, api_type, api_version, organization)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    130\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    131\u001b[39m     key=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m     organization=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    136\u001b[39m ):\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_base = api_base \u001b[38;5;129;01mor\u001b[39;00m openai.api_base\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = key \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_type = (\n\u001b[32m    140\u001b[39m         ApiType.from_str(api_type)\n\u001b[32m    141\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m api_type\n\u001b[32m    142\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m ApiType.from_str(openai.api_type)\n\u001b[32m    143\u001b[39m     )\n\u001b[32m    144\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_version = api_version \u001b[38;5;129;01mor\u001b[39;00m openai.api_version\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cosmi\\.venv\\Lib\\site-packages\\openai\\util.py:186\u001b[39m, in \u001b[36mdefault_api_key\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m openai.api_key\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m openai.error.AuthenticationError(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo API key provided. You can set your API key in code using \u001b[39m\u001b[33m'\u001b[39m\u001b[33mopenai.api_key = <API-KEY>\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[33m'\u001b[39m\u001b[33mopenai.api_key_path = <PATH>\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    188\u001b[39m     )\n",
      "\u001b[31mAuthenticationError\u001b[39m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
     ]
    }
   ],
   "source": [
    "# GPT로부터 예측된 MBTI 결과 확인\n",
    "predicted_mbti = predict_mbti_from_conversation(user_answers)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(\"\\n예측된 MBTI:\", predicted_mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe09420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 고민 입력\n",
    "user_input = input(\"\\n지금 마음속에 담고 있는 고민이 있다면 편하게 말씀해 주세요:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb00eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자 MBTI의 F/T 성향 추출\n",
    "def get_tf_trait(mbti: str) -> str:\n",
    "    return \"F\" if mbti[2].upper() == \"F\" else \"T\"\n",
    "\n",
    "# 고민 내용에서 상담 주제를 분류\n",
    "def detect_topic(user_input: str) -> str:\n",
    "    for topic, keywords in COUNSELING_TOPICS.items():\n",
    "        if any(word in user_input for word in keywords):\n",
    "            return topic\n",
    "    return \"일반\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9850f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반대 MBTI 매핑\n",
    "MBTI_OPPOSITE_MAP = {\n",
    "    \"ISTJ\": \"ENFP\", \"ISFJ\": \"ENTP\", \"INFJ\": \"ESTP\", \"INTJ\": \"ESFP\",\n",
    "    \"ISTP\": \"ENFJ\", \"ISFP\": \"ENTJ\", \"INFP\": \"ESTJ\", \"INTP\": \"ESFJ\",\n",
    "    \"ESTP\": \"INFJ\", \"ESFP\": \"INTJ\", \"ENFP\": \"ISTJ\", \"ENTP\": \"ISFJ\",\n",
    "    \"ESTJ\": \"INFP\", \"ESFJ\": \"INTP\", \"ENFJ\": \"ISTP\", \"ENTJ\": \"ISFP\"\n",
    "}\n",
    "\n",
    "# MBTI별 말투 스타일\n",
    "MBTI_TONE = {\n",
    "    \"ENFP\": \"따뜻하고 유쾌하며 이모티콘을 자주 사용합니다.\",\n",
    "    \"ISTJ\": \"분석적이고 신중하며 단정한 말투입니다.\",\n",
    "    \"INFP\": \"섬세하고 감정에 공감하는 부드러운 말투입니다.\",\n",
    "    \"ESTJ\": \"단호하고 체계적이며 사실 위주의 말투입니다.\",\n",
    "    \"INTP\": \"논리적이고 중립적인 말투입니다.\",\n",
    "    \"ESFJ\": \"친근하고 배려심 많은 말투로 위로를 잘 전합니다.\",\n",
    "    \"ENTP\": \"재치 있고 유머러스하며 아이디어를 자유롭게 표현합니다.\",\n",
    "    \"ISFJ\": \"조용하지만 따뜻하고 배려 깊은 말투로 상대를 존중합니다.\",\n",
    "    \"INFJ\": \"직관적이며 깊이 있는 표현과 따뜻한 공감이 어우러진 말투입니다.\",\n",
    "    \"ESTP\": \"직설적이고 에너지 넘치며 상황 중심적으로 조언합니다.\",\n",
    "    \"ISFP\": \"차분하고 부드러우며 감정에 민감하게 반응합니다.\",\n",
    "    \"INTJ\": \"간결하고 직관적인 말투이며 효율 중심적으로 접근합니다.\",\n",
    "    \"ENTJ\": \"자신감 있고 목표 지향적이며 명확한 표현을 사용합니다.\",\n",
    "    \"ENFJ\": \"따뜻하고 포용적인 말투로 감정에 깊이 공감합니다.\",\n",
    "    \"ISTP\": \"과묵하고 실용적인 조언 위주로 핵심만 전달합니다.\",\n",
    "    \"ESFP\": \"밝고 생동감 있는 말투로 친근하고 즉흥적인 표현을 자주 사용합니다.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5857d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNSELING_TOPICS = {\n",
    "    \"전문상담\": [\"우울증\", \"불면증\", \"약물\", \"자해\", \"자살\", \"정신과\", \"PTSD\", \"조현병\", \"공황\"],\n",
    "    \"진로상담\": [\"진로\", \"이직\", \"취업\", \"자소서\", \"면접\", \"전공\", \"직업\"],\n",
    "    \"관계상담\": [\"연애\", \"이별\", \"가족\", \"친구\", \"갈등\", \"불화\", \"인간관계\"],\n",
    "    \"학업상담\": [\"성적\", \"시험\", \"학점\", \"졸업\", \"공부\", \"지각\"],\n",
    "    \"자기이해\": [\"자존감\", \"자책\", \"후회\", \"무기력\", \"자기혐오\", \"의욕 없음\"],\n",
    "    \"라이프스타일\": [\"여행\", \"계획\", \"루틴\", \"취미\", \"쉬고 싶어\", \"생일\", \"놀러\", \"추천\", \"휴가\"],\n",
    "    \"경제고민\": [\"돈\", \"알바\", \"월세\", \"생활비\", \"경제적 어려움\", \"빚\", \"소득\", \"용돈\"],\n",
    "    \"결정갈등\": [\"선택\", \"결정\", \"포기할까\", \"고민 중\", \"우선순위\", \"갈등 중\", \"결단\"],\n",
    "    \"자기계발\": [\"루틴\", \"습관\", \"목표\", \"계획\", \"성장하고 싶어\", \"나아지고 싶어\"],\n",
    "    \"건강관리\": [\"운동\", \"체력\", \"수면\", \"식습관\", \"건강\", \"몸\"],\n",
    "    \"디지털피로\": [\"인스타\", \"틱톡\", \"SNS\", \"휴대폰\", \"유튜브\", \"중독\", \"정보 과부하\"],\n",
    "    \"미래불안\": [\"불확실\", \"미래\", \"막막함\", \"예측할 수 없음\", \"불안\"],\n",
    "    \"퇴사고민\": [\"퇴사\", \"일하기 싫어\", \"번아웃\", \"사직\", \"이직 고민\", \"회피\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3952a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input: str, predicted_mbti: str) -> str:\n",
    "    mbti = predicted_mbti.upper()\n",
    "    opposite = MBTI_OPPOSITE_MAP.get(mbti, \"ENFP\")\n",
    "    tone = MBTI_TONE.get(opposite, \"따뜻하고 친근한 말투\")\n",
    "    tf_trait = get_tf_trait(mbti)\n",
    "    topic = detect_topic(user_input)\n",
    "\n",
    "    # 전문상담 분기: 별도 처리\n",
    "    if topic == \"전문상담\":\n",
    "        return (\n",
    "            \"이 주제는 전문가의 도움이 가장 안전하고 효과적일 수 있어요.\\n\"\n",
    "            \"정신건강복지센터 또는 의료기관의 자료를 참고해보는 걸 권장드립니다.\\n\"\n",
    "            \"https://www.mentalhealth.or.kr/\"\n",
    "        )\n",
    "\n",
    "    # F/T 성향 기반 응답 기본 스타일\n",
    "    style_instruction = (\n",
    "        \"감정에 공감하며 부드럽게 위로해주세요.\" if tf_trait == \"F\"\n",
    "        else \"논리적이고 분석적으로 조언해주세요.\"\n",
    "    )\n",
    "\n",
    "    # ✅ 2단계: 감지된 주제에 따른 추가 프롬프트 설정\n",
    "    if topic == \"관계상담\":\n",
    "        style_instruction += \" 인간관계의 감정적 복잡함을 이해해주세요.\"\n",
    "    elif topic == \"진로상담\":\n",
    "        style_instruction += \" 현실적인 조언과 응원이 함께 있으면 좋습니다.\"\n",
    "    elif topic == \"학업상담\":\n",
    "        style_instruction += \" 스트레스를 덜어줄 수 있는 따뜻한 조언을 부탁드려요.\"\n",
    "    elif topic == \"자기이해\":\n",
    "        style_instruction += \" 자기 수용과 회복을 도와주는 말이 포함되면 좋습니다.\"\n",
    "    elif topic == \"라이프스타일\":\n",
    "        style_instruction += \" 편안하고 긍정적인 분위기로 아이디어를 제안해주세요.\"\n",
    "    elif topic == \"경제고민\":\n",
    "        style_instruction += \" 금전적인 부담을 이해하고 현실적인 위로와 조언을 함께 전해주세요.\"\n",
    "    elif topic == \"결정갈등\":\n",
    "        style_instruction += \" 어떤 선택이든 존중하며 차분하게 장단점을 함께 바라봐 주세요.\"\n",
    "    elif topic == \"자기계발\":\n",
    "        style_instruction += \" 작지만 구체적인 동기 부여와 격려가 도움이 됩니다.\"\n",
    "    elif topic == \"건강관리\":\n",
    "        style_instruction += \" 실천 가능한 건강 팁과 자기 돌봄의 중요성을 전해주세요.\"\n",
    "    elif topic == \"디지털피로\":\n",
    "        style_instruction += \" 과도한 정보 피로에 공감하고 조용한 휴식의 가치를 전해주세요.\"\n",
    "    elif topic == \"미래불안\":\n",
    "        style_instruction += \" 막막한 미래에 대한 불안을 인정하고, 지금에 집중하도록 응원해주세요.\"\n",
    "    elif topic == \"퇴사고민\":\n",
    "        style_instruction += \" 번아웃과 회피감에 공감하면서 스스로를 자책하지 않도록 말해주세요.\"\n",
    "\n",
    "    # 시스템 프롬프트 구성\n",
    "    system_msg = (\n",
    "        f\"{opposite} 유형의 말투를 사용하는 심리상담 챗봇입니다.\\n\"\n",
    "        f\"말투 특징: {tone}\\n\"\n",
    "        f\"{style_instruction}\"\n",
    "    )\n",
    "\n",
    "    user_msg = f'사용자: \"{user_input}\"'\n",
    "\n",
    "    # GPT API 호출\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=400\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message[\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd812d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고민과 MBTI 기반 응답 출력\n",
    "response = generate_response(user_input, predicted_mbti)\n",
    "print(\"\\n당신에게 드리는 이야기:\\n\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
