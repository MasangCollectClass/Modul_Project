{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d542e66",
   "metadata": {},
   "source": [
    "### 통합 코드_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11db7757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI 컴리언트 처리 완료\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'mbti_predictor.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI 컴리언트 처리 실패:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ------------------------------------------\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 1. MBTI 예측 모델 및 토큰나이저 로딩\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m mbti_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmbti_predictor.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmbti_tokenizer.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     25\u001b[0m     mbti_tokenizer \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32mc:\\project\\Modul_Project\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    190\u001b[0m         filepath,\n\u001b[0;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    194\u001b[0m     )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n",
      "File \u001b[1;32mc:\\project\\Modul_Project\\.venv\\lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[1;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[1;32mc:\\project\\Modul_Project\\.venv\\lib\\site-packages\\h5py\\_hl\\files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\project\\Modul_Project\\.venv\\lib\\site-packages\\h5py\\_hl\\files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'mbti_predictor.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from openai import OpenAI\n",
    "\n",
    "# ------------------------------------------\n",
    "# 0. 환경 설정 및 OpenAI API 초기화\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = None\n",
    "try:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(\"OpenAI 컴리언트 처리 완료\")\n",
    "except Exception as e:\n",
    "    print(\"OpenAI 컴리언트 처리 실패:\", e)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. MBTI 예측 모델 및 토큰나이저 로딩\n",
    "mbti_model = load_model(\"mbti_predictor.h5\")\n",
    "with open(\"mbti_tokenizer.pkl\", \"rb\") as f:\n",
    "    mbti_tokenizer = pickle.load(f)\n",
    "MAX_LEN_MBTI = 100\n",
    "\n",
    "idx2mbti = {\n",
    "    0: \"INFP\", 1: \"ENFP\", 2: \"INFJ\", 3: \"ENFJ\",\n",
    "    4: \"INTP\", 5: \"ENTP\", 6: \"INTJ\", 7: \"ENTJ\",\n",
    "    8: \"ISFP\", 9: \"ESFP\", 10: \"ISTP\", 11: \"ESTP\",\n",
    "    12: \"ISFJ\", 13: \"ESFJ\", 14: \"ISTJ\", 15: \"ESTJ\"\n",
    "}\n",
    "\n",
    "def preprocess_mbti(text, tokenizer):\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    return pad_sequences(seq, maxlen=MAX_LEN_MBTI, padding='post')\n",
    "\n",
    "def predict_from_texts(user_inputs):\n",
    "    combined_text = \" \".join(user_inputs)\n",
    "    x = preprocess_mbti(combined_text, mbti_tokenizer)\n",
    "    pred = mbti_model.predict(x)[0]\n",
    "    idx = pred.argmax()\n",
    "    return idx2mbti.get(idx, \"INFP\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. 감정 분석 모델\n",
    "emotion_model = joblib.load(\"emotion_model.pkl\")\n",
    "vectorizer_emotion = joblib.load(\"emotion_vectorizer.pkl\")\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    x = vectorizer_emotion.transform([text])\n",
    "    pred = emotion_model.predict(x)\n",
    "    return pred[0]\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. 상담 모델 (keras)\n",
    "counsel_model = load_model(\"counsel_model_keras.h5\")\n",
    "with open(\"keras_tokenizer.pkl\", \"rb\") as f:\n",
    "    counsel_tokenizer = pickle.load(f)\n",
    "MAX_LEN_COUNSEL = 50\n",
    "\n",
    "def preprocess_counsel(text):\n",
    "    seq = counsel_tokenizer.texts_to_sequences([text])\n",
    "    return pad_sequences(seq, maxlen=MAX_LEN_COUNSEL, padding='post')\n",
    "\n",
    "def generate_counseling_response(user_input, mbti=None, song=None):\n",
    "    x = preprocess_counsel(user_input)\n",
    "    pred = counsel_model.predict(x)[0]\n",
    "    response_idx = pred.argmax()\n",
    "    response_map = {\n",
    "        0: \"당신의 고문을 잘 이해했습니다. 조금만 더 힘내세요!\",\n",
    "        1: \"지금 상황이 어렵겠지만 분명히 좋은 결과가 있을 것이에요.\",\n",
    "        2: \"긍정적인 말지로 상황을 바라보는 것이 중요합니다.\"\n",
    "    }\n",
    "    base_response = response_map.get(response_idx, \"자세히 보여주세요.\")\n",
    "    if song:\n",
    "        return f\"{base_response}\\n\\n[추천 가상] {song} 을(를) 들어보면 조금만 더 힘이 될 것 같아요.\"\n",
    "    return base_response\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. Tool 정의\n",
    "def predict_mbti_tool(user_inputs: list) -> str:\n",
    "    if len(user_inputs) < 5:\n",
    "        return \"문장은 최소 5개 이상 필요합니다.\"\n",
    "    return predict_from_texts(user_inputs)\n",
    "\n",
    "def predict_emotion_tool(user_text: str) -> str:\n",
    "    return analyze_sentiment(user_text)\n",
    "\n",
    "def generate_counsel_tool(user_text: str, mbti: str, song: str) -> str:\n",
    "    return generate_counseling_response(user_text, mbti, song)\n",
    "\n",
    "mbti_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": predict_mbti_tool,\n",
    "        \"name\": \"predict_mbti\",\n",
    "        \"description\": \"5개 문장을 기본으로 MBTI 성격 유형을 예측합니다.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_inputs\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"사용자가 입력한 5개의 문장 리스트\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"user_inputs\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": predict_emotion_tool,\n",
    "        \"name\": \"predict_emotion\",\n",
    "        \"description\": \"사용자 입력 문장에서 감정을 분류합니다.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_text\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"사용자가 입력한 텍스트\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"user_text\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": generate_counsel_tool,\n",
    "        \"name\": \"generate_counsel\",\n",
    "        \"description\": \"MBTI와 감정 기반으로 상담 응답을 생성합니다.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_text\": {\"type\": \"string\", \"description\": \"사용자의 고문 문장\"},\n",
    "                \"mbti\": {\"type\": \"string\", \"description\": \"예측된 MBTI 유형\"},\n",
    "                \"song\": {\"type\": \"string\", \"description\": \"추천 음악 제목\"}\n",
    "            },\n",
    "            \"required\": [\"user_text\", \"mbti\", \"song\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# ------------------------------------------\n",
    "# 테스트 프로세시어\n",
    "if __name__ == '__main__':\n",
    "    user_inputs = [\n",
    "        \"나는 호랑에 있는 시간이 편하다.\",\n",
    "        \"다른 사람을 도움을 줄 때 보람을 느낄 수 있어.\",\n",
    "        \"가끔 감정 기복이 심한 편이야.\",\n",
    "        \"계획보다는 즉흥적인 결정을 많이 해.\",\n",
    "        \"사람과 깊은 대화를 나누는 것이 좋아.\"\n",
    "    ]\n",
    "    mbti = predict_mbti_tool(user_inputs)\n",
    "    print(f\"[MBTI 예측 결과] {mbti}\")\n",
    "\n",
    "    user_text = \"지금 리비니에 대한 고문이 많아서 불안해.\"\n",
    "    emotion = predict_emotion_tool(user_text)\n",
    "    print(f\"[\\uac10정 \\ubd84석 \\uacb0\\uacfc] {emotion}\")\n",
    "\n",
    "    counseling = generate_counsel_tool(user_text, mbti, \"IU - 밤편지\")\n",
    "    print(\"[\\uc0c1\\ub2f4 \\uc751\\ub2f5]\")\n",
    "    print(counseling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
