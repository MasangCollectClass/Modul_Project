{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d542e66",
   "metadata": {},
   "source": [
    "### 통합 코드_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11db7757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI 클라이언트 초기화 완료\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'mbti_predictor.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI 클라이언트 초기화 실패:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ------------------------------------------\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 1. MBTI 예측 모델 및 토크나이저 로딩\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m mbti_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmbti_predictor.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmbti_tokenizer.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     25\u001b[0m     mbti_tokenizer \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32mc:\\project\\Modul_Project\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    190\u001b[0m         filepath,\n\u001b[0;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    194\u001b[0m     )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n",
      "File \u001b[1;32mc:\\project\\Modul_Project\\.venv\\lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[1;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[1;32mc:\\project\\Modul_Project\\.venv\\lib\\site-packages\\h5py\\_hl\\files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\project\\Modul_Project\\.venv\\lib\\site-packages\\h5py\\_hl\\files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'mbti_predictor.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from openai import OpenAI\n",
    "\n",
    "# ------------------------------------------\n",
    "# 0. 환경 설정 및 OpenAI API 초기화\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = None\n",
    "try:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(\"OpenAI 클라이언트 초기화 완료\")\n",
    "except Exception as e:\n",
    "    print(\"OpenAI 클라이언트 초기화 실패:\", e)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. MBTI 예측 모델 및 토크나이저 로딩\n",
    "mbti_model = load_model(\"mbti_predictor.h5\")\n",
    "with open(\"mbti_tokenizer.pkl\", \"rb\") as f:\n",
    "    mbti_tokenizer = pickle.load(f)\n",
    "MAX_LEN_MBTI = 100\n",
    "\n",
    "idx2mbti = {\n",
    "    0: \"INFP\", 1: \"ENFP\", 2: \"INFJ\", 3: \"ENFJ\",\n",
    "    4: \"INTP\", 5: \"ENTP\", 6: \"INTJ\", 7: \"ENTJ\",\n",
    "    8: \"ISFP\", 9: \"ESFP\", 10: \"ISTP\", 11: \"ESTP\",\n",
    "    12: \"ISFJ\", 13: \"ESFJ\", 14: \"ISTJ\", 15: \"ESTJ\"\n",
    "}\n",
    "\n",
    "def preprocess_mbti(text, tokenizer):\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    return pad_sequences(seq, maxlen=MAX_LEN_MBTI, padding='post')\n",
    "\n",
    "def predict_mbti(text):\n",
    "    x = preprocess_mbti(text, mbti_tokenizer)\n",
    "    pred = mbti_model.predict(x)[0]\n",
    "    idx = pred.argmax()\n",
    "    return idx2mbti.get(idx, \"INFP\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. 감정 분석 모델 및 벡터라이저 로딩 (joblib)\n",
    "emotion_model = joblib.load(\"emotion_model.pkl\")\n",
    "vectorizer_emotion = joblib.load(\"emotion_vectorizer.pkl\")\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    x = vectorizer_emotion.transform([text])\n",
    "    pred = emotion_model.predict(x)\n",
    "    return pred[0]\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. 상담 모델 및 토크나이저 로딩 (keras)\n",
    "counsel_model = load_model(\"counsel_model_keras.h5\")\n",
    "with open(\"keras_tokenizer.pkl\", \"rb\") as f:\n",
    "    counsel_tokenizer = pickle.load(f)\n",
    "MAX_LEN_COUNSEL = 50\n",
    "\n",
    "def preprocess_counsel(text):\n",
    "    seq = counsel_tokenizer.texts_to_sequences([text])\n",
    "    return pad_sequences(seq, maxlen=MAX_LEN_COUNSEL, padding='post')\n",
    "\n",
    "def generate_counsel_response(user_input):\n",
    "    x = preprocess_counsel(user_input)\n",
    "    pred = counsel_model.predict(x)[0]\n",
    "    # pred 처리 방법에 따라 다름, 예: 인덱스 argmax or 특정 decoding 필요\n",
    "    # 여기서는 예시로 argmax 후 간단한 응답 매핑 가정\n",
    "    response_idx = pred.argmax()\n",
    "    # 간단한 매핑 예시 (실제 프로젝트에 맞게 수정 필요)\n",
    "    response_map = {\n",
    "        0: \"당신의 고민을 잘 이해했습니다. 조금만 더 힘내세요!\",\n",
    "        1: \"지금 상황이 어렵겠지만 분명히 좋은 결과가 있을 거예요.\",\n",
    "        2: \"긍정적인 마음으로 상황을 바라보는 것이 중요합니다.\",\n",
    "    }\n",
    "    return response_map.get(response_idx, \"제가 이해하기 어려운 내용입니다. 조금 더 구체적으로 말씀해 주세요.\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. GPT 상담 응답 생성기 (필요 시 사용)\n",
    "MBTI_TONE = {\n",
    "    \"ENFP\": \"따뜻하고 유쾌하며 이모티콘을 자주 사용합니다.\",\n",
    "    \"ISTJ\": \"분석적이고 신중하며 단정한 말투입니다.\",\n",
    "    \"INFP\": \"섬세하고 감정에 공감하는 부드러운 말투입니다.\",\n",
    "    \"ESTJ\": \"단호하고 체계적이며 사실 위주의 말투입니다.\",\n",
    "    \"INTP\": \"논리적이고 중립적인 말투입니다.\",\n",
    "    \"ESFJ\": \"친근하고 배려심 많은 말투로 위로를 잘 전합니다.\",\n",
    "    \"ENTP\": \"재치 있고 유머러스하며 아이디어를 자유롭게 표현합니다.\",\n",
    "    \"ISFJ\": \"조용하지만 따뜻하고 배려 깊은 말투로 상대를 존중합니다.\",\n",
    "    \"INFJ\": \"직관적이며 깊이 있는 표현과 따뜻한 공감이 어우러진 말투입니다.\",\n",
    "    \"ESTP\": \"직설적이고 에너지 넘치며 상황 중심적으로 조언합니다.\",\n",
    "    \"ISFP\": \"차분하고 부드러우며 감정에 민감하게 반응합니다.\",\n",
    "    \"INTJ\": \"간결하고 직관적인 말투이며 효율 중심적으로 접근합니다.\",\n",
    "    \"ENTJ\": \"자신감 있고 목표 지향적이며 명확한 표현을 사용합니다.\",\n",
    "    \"ENFJ\": \"따뜻하고 포용적인 말투로 감정에 깊이 공감합니다.\",\n",
    "    \"ISTP\": \"과묵하고 실용적인 조언 위주로 핵심만 전달합니다.\",\n",
    "    \"ESFP\": \"밝고 생동감 있는 말투로 친근하고 즉흥적인 표현을 자주 사용합니다.\"\n",
    "}\n",
    "\n",
    "MBTI_OPPOSITE_MAP = {\n",
    "    \"ISTJ\": \"ENFP\", \"ISFJ\": \"ENTP\", \"INFJ\": \"ESTP\", \"INTJ\": \"ESFP\",\n",
    "    \"ISTP\": \"ENFJ\", \"ISFP\": \"ENTJ\", \"INFP\": \"ESTJ\", \"INTP\": \"ESFJ\",\n",
    "    \"ESTP\": \"INFJ\", \"ESFP\": \"INTJ\", \"ENFP\": \"ISTJ\", \"ENTP\": \"ISFJ\",\n",
    "    \"ESTJ\": \"INFP\", \"ESFJ\": \"INTP\", \"ENFJ\": \"ISTP\", \"ENTJ\": \"ISFP\"\n",
    "}\n",
    "\n",
    "def get_tf_trait(mbti): \n",
    "    return \"F\" if mbti[2] == \"F\" else \"T\"\n",
    "\n",
    "def generate_gpt_response(user_input, mbti):\n",
    "    if client is None:\n",
    "        return \"OpenAI API 키가 설정되지 않았습니다.\"\n",
    "\n",
    "    tf_trait = get_tf_trait(mbti)\n",
    "    tone = MBTI_TONE.get(MBTI_OPPOSITE_MAP.get(mbti, \"ENFP\"))\n",
    "    instruction = \"감정에 공감하며 부드럽게 위로해주세요.\" if tf_trait == \"F\" else \"논리적으로 조언해주세요.\"\n",
    "    system_msg = f\"{MBTI_OPPOSITE_MAP.get(mbti)} 말투의 심리상담 챗봇입니다.\\n말투: {tone}\\n{instruction}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5. 사용자 입력 예시 & 실행\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n안녕하세요! MBTI 예측 챗봇입니다.\\n아래에 5개 문장을 입력해 주세요:\")\n",
    "    session_inputs = [input(f\"문장 {i+1}: \").strip() for i in range(5)]\n",
    "    combined_text = \" \".join(session_inputs)\n",
    "    predicted_mbti = predict_mbti(combined_text)\n",
    "    print(f\"\\n[예측된 MBTI]: {predicted_mbti}\")\n",
    "\n",
    "    user_input = input(\"\\n고민을 입력하세요: \")\n",
    "\n",
    "    detected_emotion = analyze_sentiment(user_input)\n",
    "    print(f\"\\n[감정 분석 결과]: {detected_emotion}\")\n",
    "\n",
    "    # 상담 답변: 두 가지 방식 중 선택\n",
    "    # 1) keras 상담 모델 기반\n",
    "    counsel_reply = generate_counsel_response(user_input)\n",
    "    print(\"\\n[상담 모델 응답]:\")\n",
    "    print(counsel_reply)\n",
    "\n",
    "    # 2) OpenAI GPT API 상담 응답 (원하면 주석 해제해서 사용)\n",
    "    # gpt_reply = generate_gpt_response(user_input, predicted_mbti)\n",
    "    # print(\"\\n[GPT 상담 응답]:\")\n",
    "    # print(gpt_reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
