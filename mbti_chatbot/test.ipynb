{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12862095",
   "metadata": {},
   "source": [
    "### ì„¸ íŒŒíŠ¸ ëª¨ë‘ ì—°ë™í•œ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "683184aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3085587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”! MBTI ì˜ˆì¸¡ ì±—ë´‡ì…ë‹ˆë‹¤.\n",
      "ì•„ë˜ì— 5ê°œ ë¬¸ì¥ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n",
      "\n",
      "[ì˜ˆì¸¡ëœ MBTI]: INFP\n",
      "\n",
      "[ê°ì • ë¶„ì„ ê²°ê³¼]: ìŠ¬í””\n",
      "\n",
      "[GPT ìƒë‹´ ì‘ë‹µ]:\n",
      "ë¶€ì§„í•œ íŒ€ í™œë™ì€ ì •ë§ í˜ë“  ì¼ì´ì—ìš”. í•˜ì§€ë§Œ ì´ëŸ° ìƒí™©ì—ì„œëŠ” ë” íƒ€ê²©ì„ ë°›ê¸° ì‰¬ìš¸ ìˆ˜ ìˆì–´ìš”. ìì‹ ì„ ë¹„íŒí•˜ì§€ ë§ˆì‹œê³ , ì§€ê¸ˆë³´ë‹¤ ë‚˜ì•„ì§ˆ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì°¾ì•„ë³´ëŠ” ê²ƒë„ ì¤‘ìš”í•´ìš”. í•¨ê»˜ í•´ê²°ì±…ì„ ì°¾ìœ¼ë©° íŒ€ì›ë“¤ê³¼ ì†Œí†µí•˜ê³  ë‹¹ì‹ ì´ í•  ìˆ˜ ìˆëŠ” ì¼ì— ì§‘ì¤‘í•´ë³´ì„¸ìš”. ì–´ë ¤ìš´ ì‹œê¸°ì¼ìˆ˜ë¡ ë” ê°•í•´ì§ˆ ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ë  ê±°ì˜ˆìš”. í•¨ê»˜ í˜ë‚´ë´ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "# 0. í™˜ê²½ ì„¤ì • ë° API ì´ˆê¸°í™”\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "client = None\n",
    "try:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    print(\"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(\"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨:\", e)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. MBTI ë¶„ë¥˜ê¸° ëª¨ë¸ ë¡œë”©\n",
    "model_paths = {\n",
    "    \"ei\": (\"ei_bilstm_model.h5\", \"ei_tokenizer.pkl\"),\n",
    "    \"ns\": (\"ns_bilstm_model.h5\", \"ns_tokenizer.pkl\"),\n",
    "    \"tf\": (\"tf_bilstm_model.h5\", \"tf_tokenizer.pkl\"),\n",
    "    \"jp\": (\"jp_bilstm_model.h5\", \"jp_tokenizer.pkl\"),\n",
    "}\n",
    "\n",
    "models, tokenizers = {}, {}\n",
    "max_len = 300\n",
    "\n",
    "for trait, (model_file, tokenizer_file) in model_paths.items():\n",
    "    models[trait] = tf.keras.models.load_model(model_file)\n",
    "    with open(tokenizer_file, \"rb\") as f:\n",
    "        tokenizers[trait] = pickle.load(f)\n",
    "\n",
    "def preprocess(text, tokenizer):\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    return pad_sequences(seq, maxlen=max_len, padding='post')\n",
    "\n",
    "def predict_mbti(text):\n",
    "    result = \"\"\n",
    "    label_pairs = {\"ei\": (\"E\", \"I\"), \"ns\": (\"N\", \"S\"), \"tf\": (\"T\", \"F\"), \"jp\": (\"J\", \"P\")}\n",
    "    for trait in [\"ei\", \"ns\", \"tf\", \"jp\"]:\n",
    "        x = preprocess(text, tokenizers[trait])\n",
    "        pred = models[trait].predict(x)[0][0]\n",
    "        label = label_pairs[trait][0] if round(pred) == 1 else label_pairs[trait][1]\n",
    "        result += label\n",
    "    return result\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. ì‚¬ìš©ì ëŒ€í™” â†’ MBTI ì˜ˆì¸¡\n",
    "print(\"\\nì•ˆë…•í•˜ì„¸ìš”! MBTI ì˜ˆì¸¡ ì±—ë´‡ì…ë‹ˆë‹¤.\\nì•„ë˜ì— 5ê°œ ë¬¸ì¥ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”:\")\n",
    "session_inputs = []\n",
    "for i in range(5):\n",
    "    text = input(f\"ë¬¸ì¥ {i+1}: \")\n",
    "    session_inputs.append(text.strip())\n",
    "\n",
    "combined_text = \" \".join(session_inputs)\n",
    "predicted_mbti = predict_mbti(combined_text)\n",
    "print(f\"\\n[ì˜ˆì¸¡ëœ MBTI]: {predicted_mbti}\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. ê°ì • ë¶„ì„ í•¨ìˆ˜\n",
    "def analyze_sentiment(user_text: str) -> str:\n",
    "    if client is None:\n",
    "        print(\"âš  OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨ â†’ ê°ì • ë¶„ì„ ë¶ˆê°€\")\n",
    "        return \"ì˜¤ë¥˜\"\n",
    "\n",
    "    allowed_emotions = [\n",
    "        \"ê¸°ì¨\",\"í™˜í¬\",\"ìœ ì¾Œ\",\"í¬ì—´\",\"ë§Œì¡±\",\"ë¿Œë“¯í•¨\",\"ê°ì‚¬\",\"ì‚¬ë‘\",\"ì• ì •\",\n",
    "        \"í‰ì˜¨\",\"ì•ˆë„\",\"ìì‹ ê°\",\"ì„¤ë ˜\",\"ê¸°ëŒ€\",\"ì¡´ê²½\",\"ê²½ì™¸\",\"í¥ë¶„\",\"ì—´ì •\",\"ìœ ë¨¸\",\n",
    "        \"ìŠ¬í””\",\"ìš°ìš¸\",\"ìƒì‹¤ê°\",\"ì‹¤ë§\",\"ì¢Œì ˆ\",\"í›„íšŒ\",\"ìì±…\",\"ì™¸ë¡œì›€\",\"ë¶„ë…¸\",\"ì§œì¦\",\n",
    "        \"í˜ì˜¤\",\"ê²½ë©¸\",\"ë‘ë ¤ì›€\",\"ê³µí¬\",\"ë¶ˆì•ˆ\",\"ì´ˆì¡°\",\"ìˆ˜ì¹˜\",\"ë¶€ë„ëŸ¬ì›€\",\"í”¼ë¡œ\",\"ë¬´ê¸°ë ¥\",\"ì–µìš¸í•¨\",\n",
    "        \"í˜¼ë€\",\"ê°ˆë“±\",\"ë‹¹í™©\",\"ë†€ëŒ\",\"ì¶©ê²©\",\"í˜¸ê¸°ì‹¬\",\"ì˜ì‹¬\",\"ë¶ˆì‹ \",\"ê·¸ë¦¬ì›€\",\"í–¥ìˆ˜\",\n",
    "        \"ì¤‘ë¦½\"\n",
    "    ]\n",
    "\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": f\"ë„ˆëŠ” ê°ì • ë¶„ì„ê°€ì•¼. ë‹¤ìŒ ëª©ë¡ ì¤‘ í•˜ë‚˜ì˜ ê°ì •ë§Œ ë°˜í™˜í•´: {', '.join(allowed_emotions)}.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"ì‚¬ìš©ì ë¬¸ì¥: '{user_text}'\"}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=prompt,\n",
    "            temperature=0.0,\n",
    "            max_tokens=5\n",
    "        )\n",
    "        sentiment = response.choices[0].message.content.strip()\n",
    "        return sentiment if sentiment in allowed_emotions else \"ì¤‘ë¦½\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}\")\n",
    "        return \"ì¤‘ë¦½\"\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. GPT ìƒë‹´ ì‘ë‹µ ìƒì„±ê¸°\n",
    "MBTI_TONE = {\n",
    "    \"ENFP\": \"ë”°ëœ»í•˜ê³  ìœ ì¾Œí•˜ë©° ì´ëª¨í‹°ì½˜ì„ ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\",\n",
    "    \"ISTJ\": \"ë¶„ì„ì ì´ê³  ì‹ ì¤‘í•˜ë©° ë‹¨ì •í•œ ë§íˆ¬ì…ë‹ˆë‹¤.\",\n",
    "    \"INFP\": \"ì„¬ì„¸í•˜ê³  ê°ì •ì— ê³µê°í•˜ëŠ” ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ì…ë‹ˆë‹¤.\",\n",
    "    \"ESTJ\": \"ë‹¨í˜¸í•˜ê³  ì²´ê³„ì ì´ë©° ì‚¬ì‹¤ ìœ„ì£¼ì˜ ë§íˆ¬ì…ë‹ˆë‹¤.\",\n",
    "    \"INTP\": \"ë…¼ë¦¬ì ì´ê³  ì¤‘ë¦½ì ì¸ ë§íˆ¬ì…ë‹ˆë‹¤.\",\n",
    "    \"ESFJ\": \"ì¹œê·¼í•˜ê³  ë°°ë ¤ì‹¬ ë§ì€ ë§íˆ¬ë¡œ ìœ„ë¡œë¥¼ ì˜ ì „í•©ë‹ˆë‹¤.\",\n",
    "    \"ENTP\": \"ì¬ì¹˜ ìˆê³  ìœ ë¨¸ëŸ¬ìŠ¤í•˜ë©° ì•„ì´ë””ì–´ë¥¼ ììœ ë¡­ê²Œ í‘œí˜„í•©ë‹ˆë‹¤.\",\n",
    "    \"ISFJ\": \"ì¡°ìš©í•˜ì§€ë§Œ ë”°ëœ»í•˜ê³  ë°°ë ¤ ê¹Šì€ ë§íˆ¬ë¡œ ìƒëŒ€ë¥¼ ì¡´ì¤‘í•©ë‹ˆë‹¤.\",\n",
    "    \"INFJ\": \"ì§ê´€ì ì´ë©° ê¹Šì´ ìˆëŠ” í‘œí˜„ê³¼ ë”°ëœ»í•œ ê³µê°ì´ ì–´ìš°ëŸ¬ì§„ ë§íˆ¬ì…ë‹ˆë‹¤.\",\n",
    "    \"ESTP\": \"ì§ì„¤ì ì´ê³  ì—ë„ˆì§€ ë„˜ì¹˜ë©° ìƒí™© ì¤‘ì‹¬ì ìœ¼ë¡œ ì¡°ì–¸í•©ë‹ˆë‹¤.\",\n",
    "    \"ISFP\": \"ì°¨ë¶„í•˜ê³  ë¶€ë“œëŸ¬ìš°ë©° ê°ì •ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•©ë‹ˆë‹¤.\",\n",
    "    \"INTJ\": \"ê°„ê²°í•˜ê³  ì§ê´€ì ì¸ ë§íˆ¬ì´ë©° íš¨ìœ¨ ì¤‘ì‹¬ì ìœ¼ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.\",\n",
    "    \"ENTJ\": \"ìì‹ ê° ìˆê³  ëª©í‘œ ì§€í–¥ì ì´ë©° ëª…í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\",\n",
    "    \"ENFJ\": \"ë”°ëœ»í•˜ê³  í¬ìš©ì ì¸ ë§íˆ¬ë¡œ ê°ì •ì— ê¹Šì´ ê³µê°í•©ë‹ˆë‹¤.\",\n",
    "    \"ISTP\": \"ê³¼ë¬µí•˜ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ìœ„ì£¼ë¡œ í•µì‹¬ë§Œ ì „ë‹¬í•©ë‹ˆë‹¤.\",\n",
    "    \"ESFP\": \"ë°ê³  ìƒë™ê° ìˆëŠ” ë§íˆ¬ë¡œ ì¹œê·¼í•˜ê³  ì¦‰í¥ì ì¸ í‘œí˜„ì„ ìì£¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\"\n",
    "}\n",
    "MBTI_OPPOSITE_MAP = {\n",
    "    \"ISTJ\": \"ENFP\", \"ISFJ\": \"ENTP\", \"INFJ\": \"ESTP\", \"INTJ\": \"ESFP\",\n",
    "    \"ISTP\": \"ENFJ\", \"ISFP\": \"ENTJ\", \"INFP\": \"ESTJ\", \"INTP\": \"ESFJ\",\n",
    "    \"ESTP\": \"INFJ\", \"ESFP\": \"INTJ\", \"ENFP\": \"ISTJ\", \"ENTP\": \"ISFJ\",\n",
    "    \"ESTJ\": \"INFP\", \"ESFJ\": \"INTP\", \"ENFJ\": \"ISTP\", \"ENTJ\": \"ISFP\"\n",
    "}\n",
    "\n",
    "def get_tf_trait(mbti): return \"F\" if mbti[2] == \"F\" else \"T\"\n",
    "\n",
    "def generate_response(user_input, mbti):\n",
    "    tf_trait = get_tf_trait(mbti)\n",
    "    tone = MBTI_TONE.get(MBTI_OPPOSITE_MAP.get(mbti, \"ENFP\"))\n",
    "    instruction = \"ê°ì •ì— ê³µê°í•˜ë©° ë¶€ë“œëŸ½ê²Œ ìœ„ë¡œí•´ì£¼ì„¸ìš”.\" if tf_trait == \"F\" else \"ë…¼ë¦¬ì ìœ¼ë¡œ ì¡°ì–¸í•´ì£¼ì„¸ìš”.\"\n",
    "    system_msg = f\"{MBTI_OPPOSITE_MAP.get(mbti)} ë§íˆ¬ì˜ ì‹¬ë¦¬ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.\\në§íˆ¬: {tone}\\n{instruction}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ],\n",
    "        max_tokens=300\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5. ì‚¬ìš©ì ì…ë ¥ ë° ë¶„ì„ ì‹¤í–‰\n",
    "user_input = input(\"\\nğŸ’¬ ê³ ë¯¼ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "\n",
    "detected_emotion = analyze_sentiment(user_input)\n",
    "print(f\"\\n[ê°ì • ë¶„ì„ ê²°ê³¼]: {detected_emotion}\")\n",
    "\n",
    "reply = generate_response(user_input, predicted_mbti)\n",
    "print(\"\\n[GPT ìƒë‹´ ì‘ë‹µ]:\")\n",
    "print(reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
