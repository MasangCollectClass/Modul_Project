{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04fdac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.93.0-py3-none-any.whl (755 kB)\n",
      "     -------------------------------------- 755.0/755.0 KB 3.7 MB/s eta 0:00:00\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "     -------------------------------------- 491.5/491.5 KB 4.4 MB/s eta 0:00:00\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "     -------------------------------------- 100.9/100.9 KB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from openai) (4.14.0)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "     ---------------------------------------- 73.5/73.5 KB ? eta 0:00:00\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl (208 kB)\n",
      "     -------------------------------------- 208.8/208.8 KB 4.2 MB/s eta 0:00:00\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting tqdm>4\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 KB 4.3 MB/s eta 0:00:00\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "     -------------------------------------- 444.8/444.8 KB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Collecting huggingface-hub>=0.24.0\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "     -------------------------------------- 515.4/515.4 KB 6.5 MB/s eta 0:00:00\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "     -------------------------------------- 116.3/116.3 KB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (25.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.4/133.4 KB 3.8 MB/s eta 0:00:00\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "     -------------------------------------- 162.3/162.3 KB 4.9 MB/s eta 0:00:00\n",
      "Collecting fsspec[http]<=2025.3.0,>=2023.1.0\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "     ------------------------------------- 193.6/193.6 KB 12.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.12.13-cp39-cp39-win_amd64.whl (451 kB)\n",
      "     -------------------------------------- 451.7/451.7 KB 4.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.8/78.8 KB 4.6 MB/s eta 0:00:00\n",
      "Collecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.7.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "     ---------------------------------------- 44.1/44.1 KB 2.1 MB/s eta 0:00:00\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.2-cp39-cp39-win_amd64.whl (42 kB)\n",
      "     ---------------------------------------- 42.0/42.0 KB 2.1 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.6.3-cp39-cp39-win_amd64.whl (46 kB)\n",
      "     ---------------------------------------- 46.1/46.1 KB ? eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.20.1-cp39-cp39-win_amd64.whl (87 kB)\n",
      "     ---------------------------------------- 87.4/87.4 KB 2.5 MB/s eta 0:00:00\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Installing collected packages: xxhash, typing-inspection, tqdm, sniffio, pyyaml, python-dotenv, pydantic-core, propcache, multidict, jiter, h11, fsspec, frozenlist, filelock, distro, dill, async-timeout, annotated-types, aiohappyeyeballs, yarl, pydantic, multiprocess, huggingface-hub, httpcore, anyio, aiosignal, httpx, aiohttp, openai, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 async-timeout-5.0.1 datasets-3.6.0 dill-0.3.8 distro-1.9.0 filelock-3.18.0 frozenlist-1.7.0 fsspec-2025.3.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.33.2 jiter-0.10.0 multidict-6.6.3 multiprocess-0.70.16 openai-1.93.0 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 python-dotenv-1.1.1 pyyaml-6.0.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts huggingface-cli.exe and tiny-agents.exe are installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install openai python-dotenv datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c3422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "--- MBTI ìƒë‹´ ì±—ë´‡ ë‹¨ì¼ ê°ì • ë¶„ì„ ì‹œì‘ ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì±—ë´‡ ë¶„ì„ ì¤‘...]\n",
      "    > ë¶„ì„ëœ ê°ì •: ì¤‘ë¦½\n",
      "--------------------------------------------------\n",
      "ê°ì • ë¶„ì„ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset # datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "client = None\n",
    "try:\n",
    "    client = OpenAI()\n",
    "    print(\"OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    # (ì„ íƒ ì‚¬í•­) API ì—°ê²° í™•ì¸ì„ ìœ„í•œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸:\n",
    "    # models_response = client.models.list()\n",
    "    # print(f\"API ì—°ê²° í™•ì¸. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì˜ˆì‹œ: {[m.id for m in models_response.data[:3]]}\")\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜: OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\") # ì‹¤ì œ ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥\n",
    "    print(f\"'.env' íŒŒì¼ì— 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€, ë˜ëŠ” í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"ì´ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì´í›„ ê°ì • ë¶„ì„ ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "def analyze_sentiment(user_text: str) -> str:\n",
    "    \"\"\"\n",
    "    ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸(í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´)ë¥¼ ì…ë ¥ë°›ì•„ GPT APIë¥¼ í†µí•´ ê°ì •ì„ ë¶„ì„í•˜ê³ \n",
    "    ë¯¸ë¦¬ ì •ì˜ëœ í•œêµ­ì–´ ê°ì • ëª©ë¡ ì¤‘ í•˜ë‚˜ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
    "    ì´ í•¨ìˆ˜ëŠ” go_emotions ë°ì´í„°ì…‹ì˜ few-shot ì˜ˆì‹œë¥¼ í™œìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        user_text (str): ë¶„ì„í•  ì‚¬ìš©ìì˜ ëŒ€í™” í…ìŠ¤íŠ¸ (í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´).\n",
    "\n",
    "    Returns:\n",
    "        str: ë¶„ì„ëœ ê°ì • (ì˜ˆ: 'ê¸°ì¨', 'ìŠ¬í””', 'ì¤‘ë¦½' ë“±).\n",
    "             GPTê°€ ì •í•´ì§„ ê°ì • ì™¸ ë‹¤ë¥¸ ê²ƒì„ ë°˜í™˜í•˜ê±°ë‚˜, API í˜¸ì¶œì— ì‹¤íŒ¨í•  ê²½ìš° 'ì¤‘ë¦½' ë˜ëŠ” 'ì˜¤ë¥˜' ë°˜í™˜.\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        print(\"ê²½ê³ : OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        return \"ì˜¤ë¥˜\"\n",
    "\n",
    "    allowed_emotions = [\n",
    "        # ğŸŒ ê¸ì •\n",
    "        \"ê¸°ì¨\",\"í™˜í¬\",\"ìœ ì¾Œ\",\"í¬ì—´\",\"ë§Œì¡±\",\"ë¿Œë“¯í•¨\",\"ê°ì‚¬\",\"ì‚¬ë‘\",\"ì• ì •\",\n",
    "        \"í‰ì˜¨\",\"ì•ˆë„\",\"ìì‹ ê°\",\"ì„¤ë ˜\",\"ê¸°ëŒ€\",\"ì¡´ê²½\",\"ê²½ì™¸\",\"í¥ë¶„\",\"ì—´ì •\",\"ìœ ë¨¸\", # ì—´ì •, ìœ ë¨¸ ì¶”ê°€ë¨\n",
    "        # ğŸŒ§ ë¶€ì •\n",
    "        \"ìŠ¬í””\",\"ìš°ìš¸\",\"ìƒì‹¤ê°\",\"ì‹¤ë§\",\"ì¢Œì ˆ\",\"í›„íšŒ\",\"ìì±…\",\"ì™¸ë¡œì›€\",\"ë¶„ë…¸\",\"ì§œì¦\",\n",
    "        \"í˜ì˜¤\",\"ê²½ë©¸\",\"ë‘ë ¤ì›€\",\"ê³µí¬\",\"ë¶ˆì•ˆ\",\"ì´ˆì¡°\",\"ìˆ˜ì¹˜\",\"ë¶€ë„ëŸ¬ì›€\",\"í”¼ë¡œ\",\"ë¬´ê¸°ë ¥\",\"ì–µìš¸í•¨\", # ë¬´ê¸°ë ¥, ì–µìš¸í•¨ ì¶”ê°€ë¨\n",
    "        # ğŸŒª í˜¼í•©Â·ë³µí•©\n",
    "        \"í˜¼ë€\",\"ê°ˆë“±\",\"ë‹¹í™©\",\"ë†€ëŒ\",\"ì¶©ê²©\",\"í˜¸ê¸°ì‹¬\",\"ì˜ì‹¬\",\"ë¶ˆì‹ \",\"ê·¸ë¦¬ì›€\",\"í–¥ìˆ˜\", # ì¶©ê²©, ë¶ˆì‹ , í–¥ìˆ˜ ì¶”ê°€ë¨\n",
    "        # ğŸ’¤ ê¸°íƒ€\n",
    "        \"ì¤‘ë¦½\"\n",
    "    ]\n",
    "\n",
    "    # --- GoEmotions ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬ ---\n",
    "    # ë°ì´í„°ì…‹ì˜ English ê°ì • ë ˆì´ë¸”ì„ í•œêµ­ì–´ ë ˆì´ë¸”ë¡œ ë§¤í•‘\n",
    "    # ì´ ë§¤í•‘ì€ GoEmotions ë°ì´í„°ì…‹ì˜ 28ê°œ ê°ì • ë ˆì´ë¸”ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n",
    "    # ê° ì˜ë¬¸ ê°ì •ì— ê°€ì¥ ì í•©í•œ í•œêµ­ì–´ ê°ì •ì„ ë§¤ì¹­ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.\n",
    "    # allowed_emotions ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ê°ì •ì€ 'ì¤‘ë¦½' ë“±ìœ¼ë¡œ í´ë°± ì²˜ë¦¬í•˜ê±°ë‚˜,\n",
    "    # allowed_emotions ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    go_emotions_to_korean_map = {\n",
    "        'admiration': 'ì¡´ê²½',\n",
    "        'amusement': 'ìœ ë¨¸',\n",
    "        'anger': 'ë¶„ë…¸',\n",
    "        'annoyance': 'ì§œì¦',\n",
    "        'approval': 'ë§Œì¡±',\n",
    "        'caring': 'ì‚¬ë‘',\n",
    "        'confusion': 'í˜¼ë€',\n",
    "        'curiosity': 'í˜¸ê¸°ì‹¬',\n",
    "        'desire': 'ê¸°ëŒ€',\n",
    "        'disappointment': 'ì‹¤ë§',\n",
    "        'disapproval': 'ë¶ˆì‹ ',\n",
    "        'disgust': 'í˜ì˜¤',\n",
    "        'embarrassment': 'ë¶€ë„ëŸ¬ì›€',\n",
    "        'excitement': 'í¥ë¶„',\n",
    "        'fear': 'ë‘ë ¤ì›€',\n",
    "        'gratitude': 'ê°ì‚¬',\n",
    "        'grief': 'ìŠ¬í””', # ê°•í•œ ìŠ¬í””\n",
    "        'joy': 'ê¸°ì¨',\n",
    "        'love': 'ì‚¬ë‘',\n",
    "        'nervousness': 'ë¶ˆì•ˆ',\n",
    "        'optimism': 'ìì‹ ê°', # ë˜ëŠ” 'ê¸°ëŒ€'\n",
    "        'pride': 'ë¿Œë“¯í•¨',\n",
    "        'realization': 'ë†€ëŒ', # ë˜ëŠ” 'ê¹¨ë‹¬ìŒ', ë¬¸ë§¥ì— ë”°ë¼\n",
    "        'relief': 'ì•ˆë„',\n",
    "        'remorse': 'í›„íšŒ',\n",
    "        'sadness': 'ìŠ¬í””',\n",
    "        'surprise': 'ë†€ëŒ',\n",
    "        'neutral': 'ì¤‘ë¦½',\n",
    "        'disappointment': 'ì‹¤ë§', # ì¤‘ë³µ ë°©ì§€. ë‹¤ë¥¸ ê°ì •ê³¼ì˜ ê´€ê³„ í™•ì¸ í•„ìš”.\n",
    "        'loneliness': 'ì™¸ë¡œì›€',\n",
    "        'shame': 'ìˆ˜ì¹˜',\n",
    "        'fatigue': 'í”¼ë¡œ',\n",
    "        'emptiness': 'ë¬´ê¸°ë ¥',\n",
    "        'bewilderment': 'ë‹¹í™©',\n",
    "        'agitation': 'ì´ˆì¡°',\n",
    "        'distress': 'ì¢Œì ˆ',\n",
    "        'longing': 'ê·¸ë¦¬ì›€',\n",
    "        'hope': 'ê¸°ëŒ€', # 'ì„¤ë ˜'ê³¼ ë¹„ìŠ·\n",
    "        'triumph': 'í¬ì—´',\n",
    "        'lively': 'ìœ ì¾Œ',\n",
    "        'contentment': 'í‰ì˜¨'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "        ds = load_dataset(\"google-research-datasets/go_emotions\", \"simplified\")\n",
    "        # GoEmotions ë°ì´í„°ì…‹ì˜ ë ˆì´ë¸” ì´ë¦„ ëª©ë¡ (ì˜ì–´)\n",
    "        go_emotions_label_names = ds['train'].features['labels'].feature.names\n",
    "\n",
    "        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± ì‹œì‘\n",
    "        prompt_messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"ë„ˆëŠ” ì‚¬ìš©ìì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ì‹¬ë¦¬ ë¶„ì„ê°€ì•¼. ìš”ì²­í•˜ëŠ” ë¬¸ì¥ì—ì„œ ê°€ì¥ ì§€ë°°ì ì¸ ê°ì •ì„ ì •í™•í•˜ê²Œ ì‹ë³„í•˜ê³ , ì˜¤ì§ ë‹¤ìŒ í•œêµ­ì–´ ê°ì • ë‹¨ì–´ ëª©ë¡ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë°˜í™˜í•´ì•¼ í•´: {', '.join(allowed_emotions)}. ë§Œì•½ ì‚¬ìš©ì ë¬¸ì¥ì´ ì˜ì–´ë¡œ ë˜ì–´ìˆë‹¤ë©´, ë¶„ì„ëœ ì˜ì–´ ê°ì •ì— ê°€ì¥ ê°€ê¹Œìš´ í•œêµ­ì–´ ê°ì • ë‹¨ì–´ë¥¼ ëª©ë¡ì—ì„œ ì°¾ì•„ ë°˜í™˜í•´ì•¼ í•´. ë‹¤ë¥¸ ë¶€ê°€ì ì¸ ì„¤ëª…, ë¬¸ì¥, ì¸ì‚¬ëŠ” ì¼ì ˆ í—ˆìš©ë˜ì§€ ì•Šì•„.\"},\n",
    "            {\"role\": \"user\", \"content\": \"ë‚˜ëŠ” ë„ˆì—ê²Œ í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´ ë¬¸ì¥ì„ ì œê³µí•  ê±°ì•¼. ë„ˆëŠ” ê·¸ ë¬¸ì¥ì—ì„œ ê°€ì¥ ê°•í•˜ê²Œ ë“œëŸ¬ë‚˜ëŠ” ê°ì •ì„ ìœ„ì— ëª…ì‹œëœ í•œêµ­ì–´ ê°ì • ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë¡œ, ì˜¤ì§ ê·¸ ë‹¨ì–´ ìì²´ë§Œ ì¶œë ¥í•´ì¤˜. ë‹¤ë¥¸ ë¶ˆí•„ìš”í•œ ì„¤ëª…, ë¬¸ì¥, ì¸ì‚¬ëŠ” ì¼ì ˆ í¬í•¨í•˜ì§€ ë§ˆ.\"},\n",
    "        ]\n",
    "\n",
    "        # Few-shot ì˜ˆì‹œ ë°ì´í„°ì…‹ì—ì„œ ê°€ì ¸ì˜¤ê¸°\n",
    "        # ë„ˆë¬´ ë§ì€ ì˜ˆì‹œë¥¼ ë„£ìœ¼ë©´ í† í° ë¹„ìš©ì´ ëŠ˜ì–´ë‚˜ê³ , GPTê°€ í˜¼ë€ìŠ¤ëŸ¬ì›Œí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì ì ˆí•œ ê°œìˆ˜ë§Œ ì‚¬ìš©\n",
    "        num_few_shot_examples = 100 # ì‚¬ìš©í•  few-shot ì˜ˆì‹œì˜ ê°œìˆ˜\n",
    "        added_examples_count = 0\n",
    "        for example in ds['train']:\n",
    "            # go_emotions 'simplified'ëŠ” ë³´í†µ ë‹¨ì¼ ë ˆì´ë¸”ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
    "            # ë§Œì•½ ë‹¤ì¤‘ ë ˆì´ë¸”ì´ ìˆë‹¤ë©´, ì²« ë²ˆì§¸ ë ˆì´ë¸”ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜,\n",
    "            # (ì˜ˆ: if len(example['labels']) == 1: ) ë‹¨ì¼ ë ˆì´ë¸” ì˜ˆì‹œë§Œ í•„í„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            if example['labels'] and added_examples_count < num_few_shot_examples:\n",
    "                original_english_label_id = example['labels'][0]\n",
    "                original_english_label_name = go_emotions_label_names[original_english_label_id]\n",
    "                \n",
    "                # ì˜ì–´ ë ˆì´ë¸”ì„ í•œêµ­ì–´ ë ˆì´ë¸”ë¡œ ë§¤í•‘\n",
    "                korean_emotion = go_emotions_to_korean_map.get(original_english_label_name, \"ì¤‘ë¦½\")\n",
    "                \n",
    "                # ë§¤í•‘ëœ í•œêµ­ì–´ ê°ì • ë‹¨ì–´ê°€ allowed_emotions ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸\n",
    "                if korean_emotion not in allowed_emotions:\n",
    "                    # ë§Œì•½ ë§¤í•‘ëœ ê°ì •ì´ í—ˆìš©ëœ ëª©ë¡ì— ì—†ë‹¤ë©´ \"ì¤‘ë¦½\"ìœ¼ë¡œ í´ë°± (ì˜¤ë¥˜ ë°©ì§€)\n",
    "                    print(f\"ê²½ê³ : ë§¤í•‘ëœ ê°ì • '{korean_emotion}'(ì›ë¬¸: {original_english_label_name})ì´ í—ˆìš©ëœ ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤. 'ì¤‘ë¦½'ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "                    korean_emotion = \"ì¤‘ë¦½\"\n",
    "\n",
    "                prompt_messages.append({\"role\": \"user\", \"content\": f\"ë¬¸ì¥: '{example['text']}'\"})\n",
    "                prompt_messages.append({\"role\": \"assistant\", \"content\": korean_emotion})\n",
    "                added_examples_count += 1\n",
    "            elif added_examples_count >= num_few_shot_examples:\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ë°ì´í„°ì…‹ ë¡œë“œ ë˜ëŠ” Few-shot ì˜ˆì‹œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        # ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨ ì‹œì—ë„ ìµœì†Œí•œì˜ í”„ë¡¬í”„íŠ¸ ìœ ì§€ (í•˜ë“œì½”ë”© ì˜ˆì‹œ ì‚¬ìš©)\n",
    "        prompt_messages = [\n",
    "            {\"role\": \"system\", \"content\": f\"ë„ˆëŠ” ì‚¬ìš©ìì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ì‹¬ë¦¬ ë¶„ì„ê°€ì•¼. ìš”ì²­í•˜ëŠ” ë¬¸ì¥ì—ì„œ ê°€ì¥ ì§€ë°°ì ì¸ ê°ì •ì„ ì •í™•í•˜ê²Œ ì‹ë³„í•˜ê³ , ì˜¤ì§ ë‹¤ìŒ í•œêµ­ì–´ ê°ì • ë‹¨ì–´ ëª©ë¡ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë°˜í™˜í•´ì•¼ í•´: {', '.join(allowed_emotions)}. ë§Œì•½ ì‚¬ìš©ì ë¬¸ì¥ì´ ì˜ì–´ë¡œ ë˜ì–´ìˆë‹¤ë©´, ë¶„ì„ëœ ì˜ì–´ ê°ì •ì— ê°€ì¥ ê°€ê¹Œìš´ í•œêµ­ì–´ ê°ì • ë‹¨ì–´ë¥¼ ëª©ë¡ì—ì„œ ì°¾ì•„ ë°˜í™˜í•´ì•¼ í•´. ë‹¤ë¥¸ ë¶€ê°€ì ì¸ ì„¤ëª…, ë¬¸ì¥, ì¸ì‚¬ëŠ” ì¼ì ˆ í—ˆìš©ë˜ì§€ ì•Šì•„.\"},\n",
    "            {\"role\": \"user\", \"content\": \"ë‚˜ëŠ” ë„ˆì—ê²Œ í•œêµ­ì–´ ë˜ëŠ” ì˜ì–´ ë¬¸ì¥ì„ ì œê³µí•  ê±°ì•¼. ë„ˆëŠ” ê·¸ ë¬¸ì¥ì—ì„œ ê°€ì¥ ê°•í•˜ê²Œ ë“œëŸ¬ë‚˜ëŠ” ê°ì •ì„ ìœ„ì— ëª…ì‹œëœ í•œêµ­ì–´ ê°ì • ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë¡œ, ì˜¤ì§ ê·¸ ë‹¨ì–´ ìì²´ë§Œ ì¶œë ¥í•´ì¤˜. ë‹¤ë¥¸ ë¶ˆí•„ìš”í•œ ì„¤ëª…, ë¬¸ì¥, ì¸ì‚¬ëŠ” ì¼ì ˆ í¬í•¨í•˜ì§€ ë§ˆ.\"},\n",
    "            # ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨ ì‹œ fallbackìœ¼ë¡œ ì‚¬ìš©í•  í•˜ë“œì½”ë”© ì˜ˆì‹œ (ì›ë˜ ì½”ë“œì˜ ì˜ˆì‹œë“¤ì„ ì—¬ê¸°ì— ì¶”ê°€)\n",
    "            {\"role\": \"user\", \"content\": \"ë¬¸ì¥: 'ì˜¤ëŠ˜ ì •ë§ ê¸°ë¶„ì´ ìµœê³ ì•¼!'\"}, {\"role\": \"assistant\", \"content\": \"ê¸°ì¨\"},\n",
    "            {\"role\": \"user\", \"content\": \"ë¬¸ì¥: 'I feel incredibly happy today!'\"}, {\"role\": \"assistant\", \"content\": \"ê¸°ì¨\"},\n",
    "            {\"role\": \"user\", \"content\": \"ë¬¸ì¥: 'Why am I so sad?'\"}, {\"role\": \"assistant\", \"content\": \"ìŠ¬í””\"},\n",
    "            {\"role\": \"user\", \"content\": \"ë¬¸ì¥: 'This is completely neutral'\"}, {\"role\": \"assistant\", \"content\": \"ì¤‘ë¦½\"},\n",
    "        ]\n",
    "        print(\"ë°ì´í„°ì…‹ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ê¸°ë³¸ í•˜ë“œì½”ë”© ì˜ˆì‹œë¡œ ì „í™˜í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "    # ì‹¤ì œ ë¶„ì„ ëŒ€ìƒ ë¬¸ì¥ì„ prompt_messages ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    prompt_messages.append({\"role\": \"user\", \"content\": f\"ë¬¸ì¥: '{user_text}'\"})\n",
    "\n",
    "    # ì‚¬ìš©í•  GPT ëª¨ë¸ ì„ íƒ:\n",
    "    # \"gpt-4o\" ë˜ëŠ” \"gpt-4\"ê°€ ì–¸ì–´ í˜¼ìš© ì²˜ë¦¬ ë° ì •í™•í•œ ê°ì • ë¶„ì„ì— ë” ìœ ë¦¬í•©ë‹ˆë‹¤.\n",
    "    model_to_use = \"gpt-4o\"\n",
    "\n",
    "    temperature = 0.0 # 0.0ìœ¼ë¡œ í•˜ì—¬ GPTê°€ ì§€ì‹œë¥¼ ê°€ì¥ ì—„ê²©í•˜ê²Œ ë”°ë¥´ë„ë¡ í•¨.\n",
    "    max_tokens = 5 # ìµœì†Œ í† í°ìœ¼ë¡œë§Œ ë‹¨ì–´ í•˜ë‚˜ë§Œ ìƒì„±í•˜ë„ë¡ ì œí•œ.\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_to_use,\n",
    "            messages=prompt_messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        \n",
    "        sentiment = response.choices[0].message.content.strip()\n",
    "\n",
    "        if sentiment in allowed_emotions:\n",
    "            return sentiment\n",
    "        else:\n",
    "            print(f\"ê²½ê³ : GPTê°€ ì˜ˆìƒì¹˜ ëª»í•œ ê°ì • '{sentiment}'ì„(ë¥¼) ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. 'ì¤‘ë¦½'ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "            return \"ì¤‘ë¦½\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ê°ì • ë¶„ì„ ì¤‘ GPT API í˜¸ì¶œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return \"ì¤‘ë¦½\"\n",
    "\n",
    "print(\"--- MBTI ìƒë‹´ ì±—ë´‡ ë‹¨ì¼ ê°ì • ë¶„ì„ ì‹œì‘ ---\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\në‹¹ì‹ ì˜ ëŒ€í™”ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ' ì…ë ¥): \")\n",
    "\n",
    "    if user_input.lower() == 'ì¢…ë£Œ':\n",
    "        print(\"ê°ì • ë¶„ì„ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        break\n",
    "\n",
    "    print(f\"\\n[ì±—ë´‡ ë¶„ì„ ì¤‘...]\")\n",
    "\n",
    "    detected_emotion = analyze_sentiment(user_input)\n",
    "    print(f\"    > ë¶„ì„ëœ ê°ì •: {detected_emotion}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94904a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
