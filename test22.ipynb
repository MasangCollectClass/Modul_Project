{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12862095",
   "metadata": {},
   "source": [
    "### 세 파트 모두 연동한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "683184aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 모델 경로\n",
    "model_paths = {\n",
    "    \"ei\": (\"models/ei_bilstm_model2.h5\", \"tokenizers/ei_tokenizer2.pkl\"),\n",
    "    \"ns\": (\"models/ns_bilstm_model.h5\", \"tokenizers/ns_tokenizer.pkl\"),\n",
    "    \"tf\": (\"models/tf_bilstm_model.h5\", \"tokenizers/tf_tokenizer.pkl\"),\n",
    "    \"jp\": (\"models/jp_bilstm_model.h5\", \"tokenizers/jp_tokenizer.pkl\"),\n",
    "}\n",
    "\n",
    "models, tokenizers = {}, {}\n",
    "max_len = 300\n",
    "\n",
    "for trait, (model_file, tokenizer_file) in model_paths.items():\n",
    "    models[trait] = tf.keras.models.load_model(model_file)\n",
    "    with open(tokenizer_file, \"rb\") as f:\n",
    "        tokenizers[trait] = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3085587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04bec2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, tokenizer):\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=300, padding='post')\n",
    "\n",
    "def predict_mbti_per_trait_threshold(text, models, tokenizers, thresholds, max_len=300):\n",
    "    label_pairs = {\"ei\": (\"E\", \"I\"), \"ns\": (\"N\", \"S\"), \"tf\": (\"T\", \"F\"), \"jp\": (\"J\", \"P\")}\n",
    "    result = \"\"\n",
    "    debug_log = []\n",
    "\n",
    "    for trait in [\"ei\", \"ns\", \"tf\", \"jp\"]:\n",
    "        tokenizer = tokenizers[trait]\n",
    "        model = models[trait]\n",
    "        seq = tokenizer.texts_to_sequences([text])\n",
    "        padded = tf.keras.preprocessing.sequence.pad_sequences(seq, maxlen=max_len, padding='post')\n",
    "        pred = model.predict(padded)[0][0]\n",
    "        threshold = thresholds.get(trait, 0.5)\n",
    "        label = label_pairs[trait][0] if pred >= threshold else label_pairs[trait][1]\n",
    "        debug_log.append((trait.upper(), pred, label))\n",
    "        result += label\n",
    "\n",
    "    return result, debug_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19daefc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "[예측 상세 로그]\n",
      "EI: 확률=0.4667 → 분류결과=E\n",
      "NS: 확률=0.7201 → 분류결과=N\n",
      "TF: 확률=0.5245 → 분류결과=F\n",
      "JP: 확률=0.4994 → 분류결과=J\n",
      "\n",
      "[최종 예측 MBTI]: ENFJ\n"
     ]
    }
   ],
   "source": [
    "# 사용자 입력 (예시 10문장)\n",
    "session_inputs = [\n",
    "    \"나는 외향적인이고 상상력이 풍부해.\",\n",
    "    \"사람들과 계획 짜는 걸 좋아하고.\",\n",
    "    \"혼자보다는 여럿이 있을 때 에너지가 생겨.\",\n",
    "    \"즉흥적인 활동이나 파티도 좋아하는 편이야.\",\n",
    "    \"새로운 사람 만나는 걸 두려워하지 않아.\",\n",
    "    \"감정에 예민해서 타인의 기분을 자주 신경 써.\",\n",
    "    \"계획보단 그때그때 하고 싶은 걸 선택해.\",\n",
    "    \"지적인 대화를 즐기지만 감정 공감도 중요해.\",\n",
    "    \"다양한 가능성을 탐색하는 걸 좋아해.\",\n",
    "    \"자유롭고 유연한 삶을 선호해.\"\n",
    "]\n",
    "\n",
    "# 문장 결합\n",
    "combined_text = \" \".join(session_inputs)\n",
    "\n",
    "# 예측 실행\n",
    "thresholds = {\"ei\": 0.45, \"ns\": 0.45, \"tf\": 0.55, \"jp\": 0.45}\n",
    "predicted_mbti, logs = predict_mbti_per_trait_threshold(combined_text, models, tokenizers, thresholds)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n[예측 상세 로그]\")\n",
    "for trait, prob, label in logs:\n",
    "    print(f\"{trait}: 확률={prob:.4f} → 분류결과={label}\")\n",
    "print(f\"\\n[최종 예측 MBTI]: {predicted_mbti}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab1ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
